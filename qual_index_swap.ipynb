{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Swapping Assignment\n",
    "### BI 622\n",
    "### Zach Goode\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average quality scores by position\n",
    "\n",
    "The script below was run as follows on the HPC:\n",
    "\n",
    ">`python ./per_bp_qual.py -f <input file> -o <output ID> -l <read length>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### outputs average quality of each position in sequence reads\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-f',dest=\"file1\", type=str, required=True, help='per_bp_qual.py -f1 <file_name>')\n",
    "parser.add_argument('-o',dest=\"file_out\", type=str, required=True, help='per_bp_qual.py -o <output_ID>')\n",
    "parser.add_argument('-l',dest=\"read_len\", type=str, required=True, help='per_bp_qual.py -l <read_length>')\n",
    "args = parser.parse_args()\n",
    "\n",
    "#variables which change depending on input options\n",
    "\n",
    "file1 = args.file1 #specified by -f\n",
    "file_naming = args.file_out #specified by -o\n",
    "read_len = args.read_len #specified by -l\n",
    "\n",
    "#Empty array with length equal to length of reads\n",
    "mean_scores=[]\n",
    "i=0\n",
    "while i < int(read_len):\n",
    "    i+=1\n",
    "    mean_scores.append(0.0)\n",
    "\n",
    "with open(file1, \"r\") as file:\n",
    "    i=0 #counter for modulus\n",
    "    NR=0 #line counter\n",
    "    for line in file:\n",
    "        i+=1\n",
    "        if i%4 == 0:\n",
    "            NR+=1\n",
    "            for bp in range(int(read_len)):\n",
    "                mean_scores[bp] = mean_scores[bp] + (ord(line[bp])-33)\n",
    "\n",
    "#create output file with unique name (e.g. \"R1_per_bp.tsv\")\n",
    "outfile1=open(file_naming+\"_per_bp.tsv\",'w')\n",
    "#header line\n",
    "outfile1.write(\"bp position\\tmean quality score\\n\")\n",
    "\n",
    "#extract and format quality scores into tsv output\n",
    "for pos in range(len(mean_scores)):\n",
    "    bp=pos+1\n",
    "    mean_pos=mean_scores[pos]/NR\n",
    "    outfile1.write(str(bp)+\"\\t\"+str(mean_pos)+\"\\n\")\n",
    "            \n",
    "outfile1.close()           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. a.\n",
    "\n",
    "# Distributions of positional quality scores\n",
    "\n",
    "(Plotted with R)\n",
    "\n",
    "![test](./per_bp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Average quality scores per read\n",
    "\n",
    "The script below was run as followson the HPC:\n",
    "\n",
    ">`python ./per_read_qual.py -f <input file> -o <output ID> -l <read length>`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "### outputs average quality per read\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-f',dest=\"file1\", type=str, required=True, help='per_bp_qual.py -f1 <file_name>')\n",
    "parser.add_argument('-o',dest=\"file_out\", type=str, required=True, help='per_bp_qual.py -o <output_ID>')\n",
    "parser.add_argument('-l',dest=\"read_len\", type=str, required=True, help='per_bp_qual.py -l <read_length>')\n",
    "args = parser.parse_args()\n",
    "\n",
    "#parameters which change depending on input file\n",
    "file1 = args.file1\n",
    "file_naming=args.file_out\n",
    "read_len=args.read_len\n",
    "\n",
    "#array holding average quality for each read\n",
    "mean_read_score=[]\n",
    "\n",
    "with open(file1, \"r\") as file:\n",
    "    i=0 # for modulus\n",
    "    NR=0 # count number of reads\n",
    "    for line in file:\n",
    "        i+=1\n",
    "        if i%4 == 0:\n",
    "            NR+=1\n",
    "            current_read=0\n",
    "            for bp in range(int(read_len)):\n",
    "                current_read = current_read + (ord(line[bp])-33)\n",
    "            mean_read_score.append(current_read)\n",
    "            \n",
    "for item in range(0,len(mean_read_score)):\n",
    "    mean_read_score[item] = mean_read_score[item]/int(read_len)\n",
    "            \n",
    "# create output file with unique name (e.g. \"R1_per_read.tsv\")          \n",
    "outfile1=open(file_naming+\"_per_read.tsv\",'w')\n",
    "# header line\n",
    "outfile1.write(\"mean quality score of read\\n\")\n",
    "\n",
    "for val in mean_read_score:\n",
    "    outfile1.write(str(val)+\"\\n\")\n",
    "            \n",
    "outfile1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions of quality scores per read\n",
    "\n",
    "## Sequence reads:\n",
    "\n",
    "![per_read_sequence](./per_read_seq.png)\n",
    "\n",
    "## Index reads:\n",
    "\n",
    "![per_read_index](./per_read_index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data for the histograms above were binned using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### bins data using numpy.histogram and outputs to tsv\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-f',dest=\"file1\", type=str, required=True, help='per_bp_qual.py -f1 <file_name>')\n",
    "parser.add_argument('-o',dest=\"file_naming\", type=str, required=True, help='per_bp_qual.py -o <name_prefix>')\n",
    "args = parser.parse_args()\n",
    "\n",
    "#input options (-f and -o)\n",
    "file=args.file1\n",
    "file_naming = args.file_naming #used as a prefix for naming output file\n",
    "\n",
    "mean_per_read=[]\n",
    "\n",
    "with open(file, 'r') as fh:\n",
    "    i=0\n",
    "    for line in fh:\n",
    "        if i > 0:\n",
    "            mean_per_read.append(float(line))\n",
    "        i+=1\n",
    "\n",
    "data = np.asarray(mean_per_read)\n",
    "bin_means = np.histogram(data, bins=20, range=(21,41))\n",
    "\n",
    "outfile=open(file_naming+\"_hist.tsv\",'w')\n",
    "\n",
    "for j in range(len(bin_means[0])):\n",
    "    outfile.write(str(bin_means[0][j])+\"\\t\"+str(int(bin_means[1][j]))+\"\\n\")\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "# 1. b.\n",
    "\n",
    "### A good cutoff for quality score appears to be around 31. This should remove most of the erroneous index pairs, while retaining the desired pairs.\n",
    "\n",
    "# 1. c.\n",
    "\n",
    "### Number of reads containings Ns in the index files:\n",
    "\n",
    ">`cat 1294_S1_L008_R2_001.fastq | awk ' NR % 4 == 2 ' | grep 'N' | wc -l`\n",
    ">\n",
    "### 3,976,613 index reads in the R2 file contain 1 or more Ns (0.27% of reads)\n",
    ">\n",
    "`cat 1294_S1_L008_R2_001.fastq | awk ' NR % 4 == 2 ' | grep 'N' | wc -l`\n",
    ">\n",
    "### 3,328,051 index reads in the R3 file contain 1 or more Ns (0.23% of reads)\n",
    "\n",
    "# 1. d.\n",
    "\n",
    "### The distribution of mean quality scores across the reads tells me that the majority of reads have an average quality of 35 or higher. The index reads, in particuluar, have lower average quality scores than the sequence reads. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Question 2\n",
    "\n",
    "### De-multiplex the samples & document index swapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1=\"test_R2.fq\"\n",
    "file2=\"test_R3.fq\"\n",
    "\n",
    "# define list of indexes used for sequencing\n",
    "indexes = [\"GTAGCGTA\", \"CGATCGAT\", \"GATCAAGG\", \"AACAGCGA\", \"TAGCCATG\", \"CGGTAATC\", \n",
    "          \"CTCTGGAT\", \"TACCGGAT\", \"CTAGCTCA\", \"CACTTCAC\", \"GCTACTCT\", \"ACGATCAG\",\n",
    "          \"TATGGCAC\", \"TGTTCCGT\", \"GTCCTAAG\", \"TCGACAAG\", \"TCTTCGAC\", \"ATCATGCG\",\n",
    "          \"ATCGTGGT\", \"TCGAGAGT\", \"TCGGATTC\", \"GATCTTGC\", \"AGAGTCCA\", \"AGGATAGC\"]\n",
    "\n",
    "# define function to reverse complement reverse sequence reads\n",
    "def rev_comp(dna):\n",
    "    dna=dna[::-1]\n",
    "    reverse_comp=\"\"\n",
    "    for bp in range(len(dna)):\n",
    "        if dna[bp] == \"A\":\n",
    "            reverse_comp+=\"T\"\n",
    "        if dna[bp] == \"T\":\n",
    "            reverse_comp+=\"A\"\n",
    "        if dna[bp] == \"G\":\n",
    "            reverse_comp+=\"C\"\n",
    "        if dna[bp] == \"C\":\n",
    "            reverse_comp+=\"G\"\n",
    "        if dna[bp] == \"N\":\n",
    "            reverse_comp+=\"N\"\n",
    "    return reverse_comp\n",
    "\n",
    "# define dict of index_pairs (key) and their counts (value)\n",
    "pair_counts = {}\n",
    "for z in range(len(indexes)):\n",
    "    pair_counts[indexes[z]]=0\n",
    "# add other categories to the dict\n",
    "pair_counts[\"Error   \"]=0\n",
    "pair_counts[\"Index_hopped\"]=0\n",
    "pair_counts[\"Total_matched\"]=0\n",
    "pair_counts[\"Total_other\"]=0\n",
    "\n",
    "\n",
    "# open both files and loop through each line at the same time\n",
    "with open(file1,'r') as R2:\n",
    "    with open(file2,'r') as R3:\n",
    "        R2_line=0 #tracks line number\n",
    "        R3_line=0\n",
    "        for line1 in R2:\n",
    "            R2_line+=1\n",
    "            line1=line1.strip()\n",
    "                \n",
    "            if R2_line%4 == 2:\n",
    "                seq1=line1\n",
    "                \n",
    "            for line2 in R3:\n",
    "                R3_line+=1\n",
    "                if R3_line%4 != 2:\n",
    "                    break\n",
    "                else:\n",
    "                    line2=line2.strip()\n",
    "                    seq2=rev_comp(line2)\n",
    "                break \n",
    "        \n",
    "            # update dictionary of counts for proper matching indexes\n",
    "            if R2_line%4 == 2:\n",
    "                if seq1 == seq2 and seq1 in indexes:\n",
    "                    pair_counts[seq1]+= 1\n",
    "                    pair_counts[\"Total_matched\"]+=1\n",
    "\n",
    "                if seq1 != seq2:\n",
    "                    if seq1 and seq2 in indexes:\n",
    "                        pair_counts[\"Index_hopped\"]+=1\n",
    "                        pair_counts[\"Total_other\"]+=1\n",
    "                    else:\n",
    "                        pair_counts[\"Error   \"]+=1\n",
    "                        pair_counts[\"Total_other\"]+=1\n",
    "\n",
    "pair_counts[\"Total    \"] = pair_counts[\"Total_matched\"]+pair_counts[\"Total_other\"]\n",
    "                    \n",
    "# format output for standard out\n",
    "print(\"--\"*23)\n",
    "print(\"Barcode\",\"Retained_pairs\", \"%\",sep=\"\\t\")\n",
    "i=0\n",
    "for key in pair_counts:\n",
    "    i+=1\n",
    "    percent = 100*float(pair_counts[key]/pair_counts[\"Total    \"])\n",
    "    print(key,pair_counts[key],round(percent,3),sep=\"\\t\")\n",
    "    if i == len(indexes):\n",
    "          print(\"---------SUMMARY---------\")\n",
    "print(\"--\"*23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output from HPC:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "----------------------------------------------\n",
    "Barcode   Retained_pairs       %\n",
    "GTAGCGTA        8119243         2.236\n",
    "CGATCGAT        5604966         1.543\n",
    "GATCAAGG        6587100         1.814\n",
    "AACAGCGA        8872034         2.443\n",
    "TAGCCATG        10629633        2.927\n",
    "CGGTAATC        5064906         1.395\n",
    "CTCTGGAT        34976387        9.632\n",
    "TACCGGAT        76363857        21.029\n",
    "CTAGCTCA        17332036        4.773\n",
    "CACTTCAC        4191388         1.154\n",
    "GCTACTCT        7416557         2.042\n",
    "ACGATCAG        7942853         2.187\n",
    "TATGGCAC        11184304        3.08\n",
    "TGTTCCGT        15733007        4.333\n",
    "GTCCTAAG        8830276         2.432\n",
    "TCGACAAG        3853350         1.061\n",
    "TCTTCGAC        42094112        11.592\n",
    "ATCATGCG        10087503        2.778\n",
    "ATCGTGGT        6887592         1.897\n",
    "TCGAGAGT        11741547        3.233\n",
    "TCGGATTC        4611350         1.27\n",
    "GATCTTGC        3641072         1.003\n",
    "AGAGTCCA        11316780        3.116\n",
    "AGGATAGC        8673180         2.388\n",
    "---------SUMMARY---------\n",
    "Error           23577867        6.493\n",
    "Index_hopped    7806306         2.15\n",
    "Total_matched   331755033       91.358\n",
    "Total_other     31384173        8.642\n",
    "Total           363139206       100.0\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical distribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![all_indexes](./demulti.png)\n",
    "\n",
    "---\n",
    "\n",
    "![summary](./demulti_summ.png)\n",
    ">\\**Note: Error refers to reads where indexes did not match, and at least one index was not recognized. This includes reads with Ns in the sequence.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
